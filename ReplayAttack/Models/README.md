**replay_attack_net_v3.dat** - trained on rgb images (120 % Dlib's face detector crop) of the slavic faces (about 5000 unique faces) with augmentation, replays were recorded on smartphone glassy display, glassy lcd monitor and another mat monitor. Test accuracy (on hollywood dataset with 255 unique faces) was 96,5 %. Model contains two output neurons, and can generate two output labels: 0 is used as 'live' face label, and 1 used as 'attack' label. Model's architecture definition can be found in appropiate [customnetwork.h](https://github.com/pi-null-mezon/FaceAntiSpoofing/blob/228c90b90d3d93c81415ca2d95b15c447d5a2222/ReplayAttack/Learner/customnetwork.h#L84) file.

**replay_attack_net_v4.dat** - slightly deeper model than *reply_attack_net_v3* trained on twice bigger dataset. Test accuracy was 96,8 %, validation accuracy was 99,75 %. Model's architecture definition can be found in appropiate [customnetwork.h](https://github.com/pi-null-mezon/FaceAntiSpoofing/blob/b5c381fd7f6bbcf39c7902addb0b33920f759a70/ReplayAttack/Learner/customnetwork.h#L101)

**replay_attack_net_v5.dat** - as deep as *reply_attack_net_v4* but shallower (#define FNUM 8 in customnetwork.h) and trained on almost same dataset (except scans of grayscale photos added in attack set). Test accuracy was 96,2 %. In non optimized environment (nor OpenBLAS or CUDA) inference takes 2 times less time compared to **v3** and **v4**. Model's architecture definition can be found in appropiate [customnetwork.h](https://github.com/pi-null-mezon/FaceAntiSpoofing/blob/b5c381fd7f6bbcf39c7902addb0b33920f759a70/ReplayAttack/Learner/customnetwork.h#L101) 

**replay_attack_net_v6.dat** - same arch as *reply_attack_net_v5*, trained on more diverse dataset, test accuracy was 95,4 %. 